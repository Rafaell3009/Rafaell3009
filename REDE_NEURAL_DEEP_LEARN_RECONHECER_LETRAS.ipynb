{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoMPfF/bakQHDiKlTYJ4NV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a8mkU82FdufL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() # Definindo a conversão de imagem para tensor\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino no dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados  por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega a parte de validação do dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados  por partes"
      ],
      "metadata": {
        "id": "2I-fXLovd_6D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conferir se a estrutura de dados esta representando a imagem corretamente com atravez da\n",
        "# representação de 1 digito\n",
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tsfao3Es4qY1",
        "outputId": "b9108556-d03b-4d60-abcf-4a441e48f30f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conferir o tamanho da imagem para conferir o seu tensor.\n",
        "print(imagens[0].shape) # Para verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) # Para verificar as dimensões do tensor de cada etiqueta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azFFJCzD9QYU",
        "outputId": "ef9fbfd4-ac18-483f-dbfc-1c2dd4ccbe83"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iserindo o  modelo de rede Keras IncepitionV3\n",
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128) # Camada de entrada 784 neuronios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # Camada linear 1, 128 neuronios se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # Camada linear 2, 64 neuronios se ligam a 10\n",
        "        # Para a camada de saída não é  necessário definir nada pois precisamos somente pegar o output\n",
        "        # da  camada interna 2\n",
        "\n",
        "    def forward(self, X):\n",
        "        x = F.relu(self.linear1(X)) # Função de ativação da camada de entrada para a camada interna 1\n",
        "        x = F.relu(self.linear2(X)) # Função de ativação da camada interna 1 para a camada interna 2\n",
        "        x = self.linear3(X) # Função de ativação da camada interna 2 para a camada de saída, nesse caso f(x)=x\n",
        "        return F.log_softmax(X, dim=1) # Dados utilizados para calcular a perda"
      ],
      "metadata": {
        "id": "GcPohctD_C9h"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Otimizador da rede (Estruturade treinamento)\n",
        "def treino(modelo, trainloader, device):\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # Define a politica de atualização dos pesos e das bias\n",
        "    inicio = time() # Time para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn.NLLLoss() # Definindo o criterio para calcular a perda\n",
        "    EPOCHS = 30 # Numero de epochs que o algoritimo rodará\n",
        "    modelo.train() # Ativando o modelo treinamento\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0 # Inicialização da perda de epoch em questão\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "            imagens = imagens.view(imagens.shape[0], -1) # Convertendo a imagem para \"vetores\" de 28*28 casas para ficarem compativeis\n",
        "            otimizador.zero_grad() # zerando os gradientes por conta dociclo anterior\n",
        "\n",
        "            output = modelo(imagens.to(device)) # Colocando os dados no modelo\n",
        "            perda_instantanea = criterio(output,etiquetas.to(device)) # Colocando os dados no modelo\n",
        "\n",
        "            perda_instantanea.backward() # Back propagation a partir da perda\n",
        "            otimizador.step() # Atualizando os pesos e as bias\n",
        "\n",
        "            perda_acumulada += perda_instantanea.item() # Atualização da perda acumulada\n",
        "\n",
        "        else:\n",
        "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "    print(\"\\nTempo de treino (em minutos) =\",(time()-inicio)/60)"
      ],
      "metadata": {
        "id": "jWOavyJVFses"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    for imagens, etiquetas in valloader:\n",
        "        for i in range(len(etiquetas)):\n",
        "            img = imagens[i].view(1, 784)\n",
        "            # Desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo auto de processamento\n",
        "            with torch.no_grad():\n",
        "                logps = modelo(img.to(device)) # Output do modelo em escala logaritmica\n",
        "\n",
        "            ps = torch.exp(logps) # Converte o output escala normal (lembrando que é um tensor)\n",
        "            probab = list(ps.cpu().numpy()[0])\n",
        "            etiqueta_pred = probab.index(max(probab)) # Converte o tensor em número, no caso, o número que o modelo previu como correto\n",
        "            etiqueta_certa = etiquetas.numpy()[i]\n",
        "            if(etiqueta_certa == etiqueta_pred):  # Compara a previsão com o valor correto\n",
        "                conta_corretas += 1\n",
        "            conta_todas += 1\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))\n"
      ],
      "metadata": {
        "id": "PtUzNveyKApS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRzEoH6AQcKm",
        "outputId": "8094aea0-d28b-46f9-ed43-b90c04d2cd20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}